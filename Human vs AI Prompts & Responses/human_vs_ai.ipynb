{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fea0d8f",
   "metadata": {},
   "source": [
    "## Human vs AI: Prompt and Response Intelligence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916b5490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100500, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"human_vs_ai_dirty.csv\")\n",
    "\n",
    "# Basic inspection\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e5300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['human_prompt', 'ai_answer_to_human_prompt',\n",
      "       'human_answer_to_human_prompt', 'ai_prompt', 'ai_answer_to_ai_prompt',\n",
      "       'human_answer_to_ai_prompt', 'response_accuracy', 'prompt_category',\n",
      "       'ai_response_length', 'human_response_length', 'ai_sentiment_score',\n",
      "       'human_sentiment_score', 'winner', 'entry_date', 'response_source',\n",
      "       'ai_readability_score', 'human_readability_score',\n",
      "       'response_relevance_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb621bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        human_prompt  \\\n",
      "0             Level guy behavior effort how trouble.   \n",
      "1  Middle certain popular enjoy particular price ...   \n",
      "2                                Spring rest accept.   \n",
      "3            Five best include finish gas education.   \n",
      "4             Seek according lay own provide inside.   \n",
      "\n",
      "                           ai_answer_to_human_prompt  \\\n",
      "0  Feel population political remain leave care po...   \n",
      "1  Attorney economy idea. Community me anything l...   \n",
      "2  Live before me education month set she. Someti...   \n",
      "3  Table condition something loss experience. War...   \n",
      "4  Around wall value. Hear save real law take. On...   \n",
      "\n",
      "                        human_answer_to_human_prompt  \\\n",
      "0  Discuss conference matter trip create suddenly...   \n",
      "1  Safe that policy speech mean light debate mode...   \n",
      "2  Late message role ever my group show. Operatio...   \n",
      "3  Turn nearly laugh war task cell speech arm. On...   \n",
      "4  Effect plant develop individual customer. Step...   \n",
      "\n",
      "                                           ai_prompt  \\\n",
      "0                                Record ago no pick.   \n",
      "1                         Way star your effort tree.   \n",
      "2                 Lawyer true our late fear us move.   \n",
      "3     Speech front answer skill money common source.   \n",
      "4  Discussion law whole nothing act spring campaign.   \n",
      "\n",
      "                              ai_answer_to_ai_prompt  \\\n",
      "0  Face wife million force tell friend south. Oft...   \n",
      "1  Move move exist already radio lawyer something...   \n",
      "2  Care our second still either. On one especiall...   \n",
      "3  War attorney where cell assume each growth pow...   \n",
      "4  Important information professional believe. Th...   \n",
      "\n",
      "                           human_answer_to_ai_prompt  response_accuracy  \\\n",
      "0  Bed senior ago structure. Book lawyer truth pr...               0.73   \n",
      "1  Factor south it anyone. Goal who far return st...               0.80   \n",
      "2  Letter also decade animal school. State him ne...               0.89   \n",
      "3  Apply study more simple no miss rule. Back ind...               0.82   \n",
      "4  Actually evidence ability increase statement b...               0.87   \n",
      "\n",
      "  prompt_category  ai_response_length  human_response_length  \\\n",
      "0          Health                  12                     16   \n",
      "1     Environment                  20                     15   \n",
      "2     Environment                  15                     23   \n",
      "3         History                  17                     12   \n",
      "4      Philosophy                  14                     15   \n",
      "\n",
      "   ai_sentiment_score  human_sentiment_score winner  entry_date  \\\n",
      "0               -0.65                   0.81     AI  16-06-1979   \n",
      "1               -0.41                  -0.05    Tie  14-11-1997   \n",
      "2                0.96                   0.72    Tie  22-01-2004   \n",
      "3                0.00                   0.38    Tie  30-05-2008   \n",
      "4               -0.21                  -0.55     AI  09-08-2004   \n",
      "\n",
      "  response_source  ai_readability_score  human_readability_score  \\\n",
      "0      ChatGPT v4                 50.24                    58.62   \n",
      "1      ChatGPT v4                 61.13                    57.00   \n",
      "2      ChatGPT v4                 76.67                    75.53   \n",
      "3      ChatGPT v4                 63.94                    62.21   \n",
      "4      ChatGPT v4                 58.62                    56.05   \n",
      "\n",
      "   response_relevance_score  \n",
      "0                      0.66  \n",
      "1                      0.83  \n",
      "2                      0.98  \n",
      "3                      0.88  \n",
      "4                      0.61  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc9e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100500 entries, 0 to 100499\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   human_prompt                  100500 non-null  object \n",
      " 1   ai_answer_to_human_prompt     99996 non-null   object \n",
      " 2   human_answer_to_human_prompt  99998 non-null   object \n",
      " 3   ai_prompt                     100500 non-null  object \n",
      " 4   ai_answer_to_ai_prompt        100500 non-null  object \n",
      " 5   human_answer_to_ai_prompt     100500 non-null  object \n",
      " 6   response_accuracy             100500 non-null  float64\n",
      " 7   prompt_category               100200 non-null  object \n",
      " 8   ai_response_length            100500 non-null  int64  \n",
      " 9   human_response_length         100500 non-null  int64  \n",
      " 10  ai_sentiment_score            100500 non-null  float64\n",
      " 11  human_sentiment_score         100500 non-null  float64\n",
      " 12  winner                        99998 non-null   object \n",
      " 13  entry_date                    100500 non-null  object \n",
      " 14  response_source               100500 non-null  object \n",
      " 15  ai_readability_score          100500 non-null  float64\n",
      " 16  human_readability_score       100500 non-null  float64\n",
      " 17  response_relevance_score      100500 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(10)\n",
      "memory usage: 13.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087b35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(496)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf471fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = df.drop_duplicates(inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f55fad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human_prompt                      0\n",
       "ai_answer_to_human_prompt       504\n",
       "human_answer_to_human_prompt    502\n",
       "ai_prompt                         0\n",
       "ai_answer_to_ai_prompt            0\n",
       "human_answer_to_ai_prompt         0\n",
       "response_accuracy                 0\n",
       "prompt_category                 300\n",
       "ai_response_length                0\n",
       "human_response_length             0\n",
       "ai_sentiment_score                0\n",
       "human_sentiment_score             0\n",
       "winner                          502\n",
       "entry_date                        0\n",
       "response_source                   0\n",
       "ai_readability_score              0\n",
       "human_readability_score           0\n",
       "response_relevance_score          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c2d0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na  = df.dropna(inplace=True)\n",
    "drop_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6696a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human_prompt                    0\n",
       "ai_answer_to_human_prompt       0\n",
       "human_answer_to_human_prompt    0\n",
       "ai_prompt                       0\n",
       "ai_answer_to_ai_prompt          0\n",
       "human_answer_to_ai_prompt       0\n",
       "response_accuracy               0\n",
       "prompt_category                 0\n",
       "ai_response_length              0\n",
       "human_response_length           0\n",
       "ai_sentiment_score              0\n",
       "human_sentiment_score           0\n",
       "winner                          0\n",
       "entry_date                      0\n",
       "response_source                 0\n",
       "ai_readability_score            0\n",
       "human_readability_score         0\n",
       "response_relevance_score        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1be54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
